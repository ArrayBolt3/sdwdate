#!/usr/bin/python3 -u

## Copyright (C) 2017 - 2018 ENCRYPTED SUPPORT LP <adrelanos@riseup.net>
## See the file COPYING for copying conditions.

import sys
import logging
import signal
import os
import glob
import time
from datetime import datetime
import random
from random import randint
from subprocess import Popen, call, PIPE, check_output
import subprocess
import json
import re
from shutil import rmtree

from sdwdate.remote_times import get_time_from_servers
from sdwdate.config import read_pools
from sdwdate.timesanitycheck import timesanitycheck
from sdwdate.timesanitycheck import time_consensus_sanity_check
from sdwdate.proxy_settings import proxy_settings

from guimessages.translations import _translations

import sdnotify

n = sdnotify.SystemdNotifier()
n.notify("READY=1")
n.notify("STATUS=Starting...")


class Pool:
    def __init__(self, pool):
        self.url, self.comment = read_pools(pool, 'production')
        self.url_random = []
        self.already_picked_index = []
        self.invalid_urls = 0
        self.done = False

    @property
    def url_range(self):
        return len(self.url)

    @property
    def allowed_failures(self):
        if os.path.exists('/etc/sdwdate.d/'):
            files = sorted(glob.glob('/etc/sdwdate.d/*.conf'))
            for f in files:
                with open(f) as conf:
                    lines = conf.readlines()
                for line in lines:
                    if line.startswith('MAX_FAILURE_RATIO'):
                        failure_ratio = re.search(r'=(.*)', line).group(1)
            return int(len(self.url) * float(failure_ratio))
        else:
            return int(len(self.url) * 0.34)
        return int(len(self.url) * 0.34)



class Sdwdate:
    def __init__(self):
        self.iteration = 0
        self.number_of_pools = 3

        self.pools = [Pool(pool) for pool in range(self.number_of_pools)]
        ## Could get it here to prevent reading the file in sdwdate_loop for each Unreachable url.
        #self.allowed_failures = [Pool(pool).allowed_failures for pool in range(self.number_of_pools)]
        self.urls = []
        self.url_random = []
        self.valid_urls = []
        self.unixtimes = []
        self.pools_diff = []
        self.invalid_urls = []
        self.url_errors = []

        self.median = 0
        self.range_nanoseconds = 999999999
        self.new_diff = 0
        self.newdiff_nanoseconds = 0

        self.sclockadj_pid = 0

        self.status_first_success_path = '/var/run/sdwdate/first_success'
        self.status_success_path = '/var/run/sdwdate/success'
        self.status_file_path = '/var/run/sdwdate/status'
        self.clock_jump_do_once_file = '/var/run/sdwdate/clock_jump_do_once'
        ## Read by whonixcheck.
        self.msg_path = '/var/run/sdwdate/msg'

        self.success_icon = 'success'
        self.busy_icon = 'busy'
        self.error_icon = 'error'

        self.status = {'icon': '', 'message': ''}

        translations_path = '/usr/share/translations/sdwdate.yaml'
        translation = _translations(translations_path, 'sdwdate')
        self._ = translation.gettext

        self.proxy_ip, self.proxy_port = proxy_settings()

    @staticmethod
    def general_proxy_error(pools):
        '''
        This error occurs (at least) when Tor is not running.
        '''
        returned_error = 'connect error: Connection closed unexpectedly'
        if (pools[0] == returned_error and
                    pools[1] == returned_error and
                    pools[2] == returned_error):
            return True
        return False

    @staticmethod
    def general_timeout_error(pools):
        '''
        This error occurs (at least) when internet connection is down.
        '''
        returned_error = 'Timeout'
        if (pools[0] == returned_error and
                    pools[1] == returned_error and
                    pools[2] == returned_error):
            return True
        return False

    @staticmethod
    def check_remote(remote, value, comment, i):
        '''
        Check returned value. True if numeric.
        '''
        pool_number = str(i)
        message = "remote " + pool_number + ": " + remote
        logger.info(message)

        message = "* comment: " + comment
        logger.info(message)

        try:
            remote_unixtime = int(value)
            old_unixtime = (time.time())
            remote_time = (datetime.strftime(datetime.fromtimestamp(remote_unixtime),
                                                   '%Y-%m-%d %H:%M:%S'))
            time_diff = int(remote_unixtime) - int(old_unixtime)
            time_diff = str(time_diff)
        except:
            message = "* status: False"
            logger.info(message)
            message = "* value: " + str(value)
            logger.info(message)
            if value == "sigterm":
               exit_handler()
            return False

        timesanitycheck_status, time_one, time_two, timesanitycheck_error = timesanitycheck(remote_unixtime)

        consensus_status, consensus_error, consensus_valid_after_str, consensus_valid_until_str = time_consensus_sanity_check(remote_unixtime)

        message = "* remote_unixtime: " + str(remote_unixtime)
        logger.info(message)
        message = "* consensus/valid-after: " + consensus_valid_after_str
        logger.info(message)
        message = "* remote_time          : " + remote_time
        logger.info(message)
        message = "* consensus/valid-until: " + consensus_valid_until_str
        logger.info(message)
        message = "* time_diff: " + time_diff + " second(s)"
        logger.info(message)

        ## Fallback.
        remote_status = "fallback"

        if timesanitycheck_status == 'sane':
            message = "* timesanitycheck: sane"
            logger.info(message)
        elif timesanitycheck_status == 'slow':
            message = "* timesanitycheck: slow"
            logger.info(message)
            remote_status = "False"
        elif timesanitycheck_status == 'fast':
            message = "* timesanitycheck: fast"
            logger.info(message)
            remote_status = "False"
        elif timesanitycheck_status == 'error':
            message = "* timesanitycheck: error: " + timesanitycheck_error
            logger.info(message)
            remote_status = "False"

        if consensus_status == 'ok':
            message = "* time_consensus_sanity_check: sane"
            logger.info(message)
            if not remote_status == "False":
                remote_status = "True"
        elif consensus_status == 'slow':
            message = "* time_consensus_sanity_check: slow"
            logger.info(message)
            remote_status = "False"
        elif consensus_status == 'fast':
            message = "* time_consensus_sanity_check: fast"
            logger.info(message)
            remote_status = "False"
        elif consensus_status == 'error':
            message = "* time_consensus_sanity_check: error: " + consensus_error
            logger.info(message)
            remote_status = "False"

        message = "* remote_status: " + str(remote_status)
        logger.info(message)

        if remote_status == "True":
            return True
        else:
            return False


    def get_comment(self, remote):
        ''' For logging the comments, get the index of the url
            to get it from pool.comment.
        '''
        url_comment = ''
        for url in self.pools:
            try:
                url_index = url.url.index(remote)
                url_comment = url.comment[url_index]
            except ValueError:
                pass
        return url_comment

    def build_median(self):
        '''
        Get the median (not average) from the list of values.
        '''
        diffs = sorted(self.pools_diff)
        message = 'Pool differences, sorted: %s' % diffs
        logger.info(message)
        self.median = diffs[(len(diffs) // 2)]
        message = 'Median time difference: %+.9f' % self.median
        logger.info(message)

    def set_new_time(self):
        '''
        Do not set time if diff = 0.
        '''
        if self.median == 0:
            message = 'Time difference = 0. Not setting time.'
            logger.info(message)
            return False
        else:
            return True

    def add_subtract_nanoseconds(self):
        signs = ['+', '-']
        sign = randint(0, 1)
        nanoseconds = randint(0, self.range_nanoseconds)
        seconds = float(nanoseconds) / 1000000000
        if sign == 1:
            seconds = seconds * -1

        self.new_diff = self.median + seconds
        self.newdiff_nanoseconds = int(self.new_diff * 1000000000)

        message = 'randomize             : %+.9f' % seconds
        logger.info(message)
        message = 'New time difference   : %+.9f' % self.new_diff
        logger.info(message)

    def run_sclockadj(self):
        cmd = '/usr/lib/sdwdate/sclockadj "' + str(self.newdiff_nanoseconds) + '"'
        message = 'Gradually adjusting the time by running sclockadj using command: %s' % cmd
        logger.info(message)

        ## Run sclockadj in a subshell.
        sclockadj = Popen(cmd, shell=True)
        self.sclockadj_pid = sclockadj.pid

        message = 'Launched sclockadj into the background. PID: %s' % self.sclockadj_pid
        logger.info(message)

    def kill_sclockadj(self):
        cmd = '/usr/lib/sdwdate/sclockadj_kill_helper'
        call(cmd, shell=True)
        self.sclockadj_pid = 0

    def set_time_using_date(self):
        old_unixtime = format(time.time(), '.9f')
        message = 'Old unixttime: ' + old_unixtime
        logger.info(message)

        new_unixtime = float(old_unixtime) + float(self.new_diff)
        new_unixtime_str = format(new_unixtime, '.9f')

        message = 'New unixtime : ' + new_unixtime_str
        logger.info(message)

        ## Set new time.
        cmd = '/bin/date --set "@' + str(new_unixtime_str) + '"'
        message = 'Instantly setting the time by using command: %s' % cmd
        logger.info(message)

        bin_date_status = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        stdout, stderr = bin_date_status.communicate()
        bin_date_status.kill()
        main_message = stdout.decode('UTF-8')
        extra_message = stderr.decode('UTF-8')
        joint_message = main_message + " " + extra_message
        message = '/bin/date output: %s' % joint_message
        logger.info(message)

        if not bin_date_status.returncode == 0:
            message = '/bin/date returncode: %s' % str(bin_date_status.returncode)
            logger.error(message)
            exit_handler()

    def sdwdate_loop(self):
        '''
        Check remotes.
        Pick a random url in each pool, check the returned value.
        Append valid urls if time is returned, otherwise restart a cycle
        with a new random url, until every pool has a time value.
        '''
        message = "Start fetching remote times."
        logger.info(message)

        fetching_msg = self._('fetching')
        restricted_msg = self._('restricted')

        status_success = os.path.exists(self.status_success_path)
        status_first_success = os.path.exists(self.status_first_success_path)
        clock_jump_do = os.path.exists(self.clock_jump_do_once_file)

        if not status_first_success:
            write_status(self.busy_icon, restricted_msg)
            message = strip_html(restricted_msg)
            logger.info(message)
        else:
            write_status(self.success_icon, fetching_msg)
            message = strip_html(fetching_msg)
            logger.info(message)

        while len(self.valid_urls) < self.number_of_pools:
            self.iteration += 1
            message = 'Running sdwdate fetch loop. iteration: %s' % self.iteration
            logger.info(message)

            ## Clear the lists.
            self.urls[:] = []
            self.url_random[:] = []

            for pool in self.pools:
                if not pool.done:
                    pool_range = pool.url_range
                    url_index = random.randrange(0, pool_range)
                    while url_index in pool.already_picked_index:
                        url_index = random.randrange(0, pool_range)

                    pool.already_picked_index.append(url_index)
                    if len(pool.already_picked_index) >= pool_range:
                        pool_number = self.pools.index(pool) + 1
                        message = self._('no_valid_time') + str(pool_number) + self._('restart')
                        logger.warning(message)
                        return self.error_icon, 'error', message

                    pool.url_random.append(pool.url[url_index])
                    self.url_random.append(pool.url[url_index])

            if len(self.url_random) > 0:
                message = 'Requested urls %s' % self.url_random
                logger.info(message)

                self.urls, self.returned_values = get_time_from_servers(self.url_random,
                                                                        self.proxy_ip,
                                                                        self.proxy_port)

                if len(self.urls) == 0:
                    message = self._('no_value_returned') + self._('restart')
                    return self.error_icon, 'error', message

                message = 'Returned urls "%s"' % self.urls
                logger.info(message)

            else:
                message = self._('list_not_built') + self._('restart')
                return self.error_icon, 'error', message

            for i in range(len(self.urls)):
                if self.check_remote(self.urls[i], self.returned_values[i], self.get_comment(self.urls[i]), i):
                    self.valid_urls.append(self.urls[i])
                    self.unixtimes.append(self.returned_values[i])
                else:
                    self.invalid_urls.append(self.urls[i])
                    self.url_errors.append(self.returned_values[i])

            if self.iteration >= 3:
               if len(self.returned_values) >= 3:
                     if self.general_proxy_error(self.returned_values):
                        message = self._('general_proxy_error')
                        return self.error_icon, 'error', message
                     if self.general_timeout_error(self.returned_values):
                        message = self._('general_timeout_error')
                        return self.error_icon, 'error', message

            for i in range(len(self.urls)):
               for pool in self.pools:
                  if self.urls[i] in pool.url_random:
                     pool.invalid_urls += 1
                     if pool.invalid_urls >= pool.allowed_failures:
                        message = (self._('max_pool_failures_1') +
                                       str(self.pools.index(pool) + 1) +
                                       ' (' + str(pool.invalid_urls) + ' of ' +
                                       str(len(pool.url)) + ')' +
                                       self._('max_pool_failures_2') + '<br>')
                        return self.error_icon, 'error', message

            old_unixtime = (time.time())

            for pool in self.pools:
                if not pool.done:
                    for url in pool.url_random:
                        pool.done = url in self.valid_urls
                        if pool.done:
                            ## Values are returned randomly. Get the index of the url.
                            index = self.valid_urls.index(url)
                            ## Pool matching web time.
                            web_unixtime = int(self.unixtimes[index])

                            web_time = (datetime.strftime(datetime.fromtimestamp(web_unixtime),
                                                              '%a %b %d %H:%M:%S UTC %Y'))
                            pool_diff = int(web_unixtime) - int(old_unixtime)
                            self.pools_diff.append(pool_diff)
                            pool_number = self.pools.index(pool) + 1
                            message = ('Pool %s: %s, web unixtime: %s, web time: %s, diff: %s seconds'
                                        % (pool_number, url, web_unixtime, web_time, pool_diff))
                            logger.info(message)

        message = "End fetching remote times."
        logger.info(message)

        message = self._('success')
        return self.success_icon, 'success', message


def exit_handler():
    n.notify("STATUS=Shutting down...")
    n.notify("WATCHDOG=1")
    n.notify("STOPPING=1")

    icon = sdwdate.error_icon
    message = sdwdate._('user_kill')
    stripped_message = strip_html(message)
    write_status(icon, message)

    if sdwdate.sclockadj_pid != 0:
        sdwdate.kill_sclockadj()

    logger.info("delete temp_dir: {}".format(temp_dir_str))
    ## rmtree can fail if exit_handler is invoked multiple times.
    try:
       rmtree(temp_dir_bytes)
    except:
       logger.info("deleting temp_dir failed: {}".format(temp_dir_str))

    logger.info(stripped_message)
    sys.exit(143)


def signal_sigterm_handler(signum, frame):
    exit_handler()


def strip_html(message):
    ## New line for log.
    tmp_message = re.sub('<br>', '\n', message)
    ## Strip remaining HTML.
    return re.sub('<[^<]+?>', '', tmp_message)


def write_status(icon, msg):
    sdwdate.status['icon'] = icon
    sdwdate.status['message'] = msg
    try:
        with open(sdwdate.status_file_path, 'w') as f:
            json.dump(sdwdate.status, f)
            f.close()
    except:
        error_msg = "Unexpected error: " + str(sys.exc_info()[0])
        print(error_msg)
        return

    with open(sdwdate.msg_path, 'w') as msgf:
        msgf.write(msg)
        msgf.close()


def prerequisite_check():
    message = ''
    previous_messsage = ''
    sdwdate = Sdwdate()
    loop_counter = 0
    loop_max = 10000
    prerequisite_check_sleep_seconds = 0
    while True:
        n.notify("WATCHDOG=1")
        if loop_counter >= loop_max:
            loop_counter = 0
        loop_counter += 1
        msg = "STATUS=Running sdwdate prerequisite_check loop. prerequisite_check_sleep_seconds: " + \
str(prerequisite_check_sleep_seconds) + " iteration: " + str(loop_counter) + " / " + str(loop_max)
        n.notify(msg)

        ## Wait one second after first failure. Two at second failure etc.
        ## Up to a maximum of ten seconds wait between attempts.
        ## The rationale behind this is to be quick at boot time while not
        ## stressing the system.
        prerequisite_check_sleep_seconds += 1
        if prerequisite_check_sleep_seconds >= 10:
            prerequisite_check_sleep_seconds = 10

        prerequisite_status = subprocess.Popen(prerequisite_path, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        stdout, stderr = prerequisite_status.communicate()
        prerequisite_status.kill()
        main_message = stdout.decode('UTF-8')
        extra_message = stderr.decode('UTF-8')
        joint_message = main_message + " " + extra_message

        if prerequisite_status.returncode == 0:
            if not extra_message == "":
               message = 'Prerequisite check: %s' % extra_message.strip()
               logger.info(strip_html(message))
            message = "Prerequisite check: " + main_message.strip()
            logger.info(strip_html(message))
            return True
        else:

            if joint_message != previous_messsage:
                previous_messsage = joint_message

                if not extra_message == "":
                    message = 'Prerequisite check: %s' % extra_message.strip()
                    logger.info(strip_html(extra_message))

                message = 'Prerequisite check: %s' % main_message.strip()
                logger.warning(strip_html(main_message))

                if prerequisite_status.returncode == 1:
                    icon = sdwdate.error_icon
                else:
                    icon = sdwdate.busy_icon

                ## TODO: remove this once security implications are sorted.
                ## https://phabricator.whonix.org/T534#15429
                main_message = "Prerequisite check not done yet. More more information, see: sdwdate-gui -> right click -> Open sdwdate's log"

                write_status(icon, main_message)

                prerequisite_check_sleep_seconds = 0
            time.sleep(prerequisite_check_sleep_seconds)


if __name__ == "__main__":
    logger = logging.getLogger('sdwdate')
    logger.setLevel(logging.INFO)
    formatter = logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s", datefmt='%Y-%m-%d %H:%M:%S')
    file_handler = logging.FileHandler('/var/log/sdwdate.log')
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)

    self_pid = os.getpid()
    pid_message = 'sdwdate started. PID: %s' % self_pid
    logger.info(pid_message)

    ## Create TEMP_DIR for te_pe_tb_check.
    temp_dir_bytes = check_output(["mktemp", "--directory"]).strip()
    temp_dir_str = temp_dir_bytes.decode("utf-8")
    logger.info("create temp_dir: {}".format(temp_dir_str))
    os.environ["TEMP_DIR"] = temp_dir_str

    run_prerequisite = False
    prerequisite_path = '/usr/lib/helper-scripts/te_pe_tb_check'
    if os.access(prerequisite_path, os.X_OK):
        run_prerequisite = True

    signal.signal(signal.SIGTERM, signal_sigterm_handler)

    sdwdate = Sdwdate()
    proxy_message = ('Tor socks host: %s Tor socks port: %s'
                     % (sdwdate.proxy_ip, sdwdate.proxy_port))
    logger.info(proxy_message)

    loop_counter = 0
    loop_max = 10000
    retry_on_error_counter = 0

    while True:
        if loop_counter >= loop_max:
            loop_counter = 0
        loop_counter += 1

        msg = "Running sdwdate main loop. iteration: " + str(loop_counter) + " / " + str(loop_max)
        logger.info(msg)

        if run_prerequisite:
            prerequisite_check()

        msg = "STATUS=Running sdwdate main loop. iteration: " + str(loop_counter) + " / " + str(loop_max)
        n.notify(msg)
        n.notify("WATCHDOG=1")

        sdwdate = Sdwdate()
        icon, status, sdwdate_message_from_loop = sdwdate.sdwdate_loop()
        n.notify("WATCHDOG=1")

        status_success = os.path.exists(sdwdate.status_success_path)
        status_first_success = os.path.exists(sdwdate.status_first_success_path)
        clock_jump_do = os.path.exists(sdwdate.clock_jump_do_once_file)

        if status == 'success':
            sdwdate.build_median()
            sdwdate.add_subtract_nanoseconds()
            if sdwdate.set_new_time():
                if not status_first_success:
                    sdwdate.set_time_using_date()
                    f = open(sdwdate.status_first_success_path, 'w')
                    f.close()
                elif clock_jump_do:
                    sdwdate.set_time_using_date()
                    f = open(sdwdate.status_first_success_path, 'w')
                    f.close()
                    os.remove(sdwdate.clock_jump_do_once_file)
                else:
                    sdwdate.run_sclockadj()

            f = open(sdwdate.status_success_path, 'w')
            f.close()

            retry_on_error_counter = 0
            ## If we make the sleep period configurable one day, we need to
            ## advice the user to also adjust WatchdogSec= in sdwdate's systemd
            ## unit file.
            sleep_time_minimum_seconds = 60 * 60
            sleep_time_maximum_seconds = 180 * 60

        elif status == 'error':
            message = "retry_on_error_counter: " + str(retry_on_error_counter)
            logger.info(message)

            retry_on_error_counter += 1

            if retry_on_error_counter >= 3:
               sleep_time_minimum_seconds = 1 * retry_on_error_counter
               sleep_time_maximum_seconds = 5 * retry_on_error_counter
               if sleep_time_maximum_seconds >= 180 * 60:
                  sleep_time_maximum_seconds = sleep_time_maximum_seconds
            else:
               sleep_time_minimum_seconds = 0
               sleep_time_maximum_seconds = 0

            log_level = 'warning'

        sleep_time_seconds = randint(sleep_time_minimum_seconds, sleep_time_maximum_seconds)
        sleep_time_minutes = sleep_time_seconds / 60

        log_level = 'info'
        message = (sdwdate_message_from_loop + " " + sdwdate._('sleeping') +
                  str(sleep_time_minutes) + sdwdate._('minutes'))
        stripped_message = strip_html(message)

        write_status(icon, message)

        if log_level == 'info':
            logger.info(stripped_message)
        elif log_level == 'warning':
            logger.warning(stripped_message)

        n.notify("WATCHDOG=1")

        range_nanoseconds = 999999999
        nanoseconds = randint(0, range_nanoseconds)

        unixtime_before_sleep = int(time.time())

        ## Using sh sleep in place of python's time.sleep(sleep_time_seconds).
        ## The latter uses the system clock for its inactive state time.
        ## It becomes utterly confused when sclockadj is running.
        cmd = "sleep" + " " + str(sleep_time_seconds) + "." + str(nanoseconds)
        message = "Running command: " + cmd
        logger.info(message)
        call(cmd, shell=True)

        if sdwdate.sclockadj_pid != 0:
            sdwdate.kill_sclockadj()

        unixtime_after_sleep = int(time.time())
        time_delta = unixtime_after_sleep - unixtime_before_sleep
        time_passed = sleep_time_seconds - time_delta

        if time_passed > 2:
           time_no_unexpected_change = False
        elif time_passed < 2:
           time_no_unexpected_change = False
        else:
           time_no_unexpected_change = True

        if time_no_unexpected_change == True:
           message = "Slept for about " + time_delta + "seconds."
           logger.warning(message)
        else:
           message = "Clock got changed by something other than sdwdate. sleep_time_seconds: " + str(sleep_time_seconds) + " time_delta: " + str(time_delta)
           logger.warning(message)
